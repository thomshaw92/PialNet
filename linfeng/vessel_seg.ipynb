{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import zipfile\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import scanf\n",
    "import SimpleITK as sitk\n",
    "import sys\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10.nii.gz', '1.nii.gz']\n"
     ]
    }
   ],
   "source": [
    "dir = 'synthetic_data/seg'\n",
    "OUT_DIR = 'synthetic_data/'\n",
    "files = os.listdir(dir)\n",
    "training_images = [os.path.join(dir, f) for f in files]\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(f):\n",
    "    niftiImage = nib.load(f).get_fdata(caching='unchanged')\n",
    "    niftiImage[tf.newaxis, ...]\n",
    "    inImage = niftiImage.astype(np.float32)\n",
    "    inImage = (inImage - inImage.mean()) / inImage.std()\n",
    "    return inImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "XT = 'validation_data/imageData.nii'\n",
    "YT = 'validation_data/segmentationData.nii'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_model(output_channels, f=2):\n",
    "    inputs = tf.keras.layers.Input(shape=(48, 48, 48, 1))\n",
    "    \n",
    "    # Downsampling through the model\n",
    "    d1 = tf.keras.layers.Conv3D(f, 3, padding='same', activation='relu')(inputs)\n",
    "    d1 = tf.keras.layers.Conv3D(f, 3, padding='same', activation='relu')(d1)\n",
    "\n",
    "    d2 = tf.keras.layers.MaxPooling3D()(d1)\n",
    "    d2 = tf.keras.layers.Conv3D(2*f, 3, padding='same', activation='relu')(d2)\n",
    "    d2 = tf.keras.layers.Conv3D(2*f, 3, padding='same', activation='relu')(d2)\n",
    "    \n",
    "    d3 = tf.keras.layers.MaxPooling3D()(d2)\n",
    "    d3 = tf.keras.layers.Conv3D(4*f, 3, padding='same', activation='relu')(d3)\n",
    "    d3 = tf.keras.layers.Conv3D(4*f, 3, padding='same', activation='relu')(d3)\n",
    "    # Upsampling and establishing the skip connections\n",
    "    u2 = tf.keras.layers.UpSampling3D()(d3)\n",
    "    u2 = tf.keras.layers.concatenate([u2, d2])\n",
    "    u2 = tf.keras.layers.Conv3D(2*f, 3, padding='same', activation='relu')(u2)\n",
    "    u2 = tf.keras.layers.Conv3D(2*f, 3, padding='same', activation='relu')(u2)\n",
    "\n",
    "    u1 = tf.keras.layers.UpSampling3D()(u2)\n",
    "    u1 = tf.keras.layers.concatenate([u1, d1])\n",
    "    u1 = tf.keras.layers.Conv3D(f, 3, padding='same', activation='relu')(u1)\n",
    "    u1 = tf.keras.layers.Conv3D(f, 3, padding='same', activation='relu')(u1)\n",
    "\n",
    "    # This is the last layer of the model.\n",
    "    outputs = tf.keras.layers.Conv3D(1, 1,activation='sigmoid')(u1)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_as_nifti(data, folder, name, affine=np.eye(4)):\n",
    "    hdr = nib.Nifti1Header()\n",
    "    hdr.set_data_dtype(np.float32)\n",
    "    img = nib.Nifti1Image(data, affine, hdr)\n",
    "    if not os.path.exists(folder):\n",
    "        os.mkdir(folder)\n",
    "    nib.save(img, os.path.join(folder, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = 'synthetic_data/raw'\n",
    "SEG = 'synthetic_data/seg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patch(img, seg, size=48):\n",
    "    def rand_seg(d, l):\n",
    "        lower = 0\n",
    "        upper = d - l\n",
    "        idx = random.randint(lower, upper)\n",
    "        idx = random.randint(lower, upper)\n",
    "        return idx, idx + l\n",
    "    d1, d2, d3 = img.shape\n",
    "    s1, s2, s3 = [rand_seg(d, size) for d in [d1, d2, d3]]\n",
    "    l1, u1 = s1\n",
    "    l2, u2 = s2\n",
    "    l3, u3 = s3\n",
    "    imgp, segp = img[l1:u1, l2:u2, l3:u3], seg[l1:u1, l2:u2, l3:u3]\n",
    "    imgp = imgp[..., tf.newaxis]\n",
    "    segp = segp[..., tf.newaxis]\n",
    "    return (imgp - imgp.mean()) / imgp.std(), segp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen(data_dir, seg_dir, images_per_batch=1, patches_per_img=4, patch_size=48):\n",
    "    data_files = os.listdir(data_dir)\n",
    "    cases = {}\n",
    "    for f in data_files:\n",
    "        case_num = scanf.scanf('%d.nii.gz', f)[0]\n",
    "        cases[case_num] = [os.path.join(data_dir, f)]\n",
    "\n",
    "    seg_files = os.listdir(seg_dir)\n",
    "    for f in seg_files:\n",
    "        case_num = scanf.scanf('%d.nii.gz', f)[0]\n",
    "        cases[case_num].append(os.path.join(seg_dir, f))\n",
    "        assert len(cases[case_num]) == 2\n",
    "    \n",
    "    data = list(cases.values())\n",
    "    \n",
    "    while True:\n",
    "        batch = random.choices(data, k=images_per_batch)\n",
    "       \n",
    "        xb, yb = [], []\n",
    "        for x, y in batch:\n",
    "            x = nib.load(x).get_fdata()\n",
    "            y = nib.load(y).get_fdata()\n",
    "            for i in range(patches_per_img):         \n",
    "                xp, yp = get_patch(x, y, size=patch_size)\n",
    "                xb.append(xp)\n",
    "                yb.append(yp)\n",
    "        xb = np.array(xb).astype('float32')\n",
    "        yb = np.array(yb)\n",
    "        yield xb, yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_131\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_70 (InputLayer)           [(None, 48, 48, 48,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_743 (Conv3D)             (None, 48, 48, 48, 2 56          input_70[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_744 (Conv3D)             (None, 48, 48, 48, 2 110         conv3d_743[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_138 (MaxPooling3D (None, 24, 24, 24, 2 0           conv3d_744[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_745 (Conv3D)             (None, 24, 24, 24, 4 220         max_pooling3d_138[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_746 (Conv3D)             (None, 24, 24, 24, 4 436         conv3d_745[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_139 (MaxPooling3D (None, 12, 12, 12, 4 0           conv3d_746[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_747 (Conv3D)             (None, 12, 12, 12, 8 872         max_pooling3d_139[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_748 (Conv3D)             (None, 12, 12, 12, 8 1736        conv3d_747[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling3d_136 (UpSampling3D (None, 24, 24, 24, 8 0           conv3d_748[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_136 (Concatenate)   (None, 24, 24, 24, 1 0           up_sampling3d_136[0][0]          \n",
      "                                                                 conv3d_746[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_749 (Conv3D)             (None, 24, 24, 24, 4 1300        concatenate_136[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_750 (Conv3D)             (None, 24, 24, 24, 4 436         conv3d_749[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling3d_137 (UpSampling3D (None, 48, 48, 48, 4 0           conv3d_750[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_137 (Concatenate)   (None, 48, 48, 48, 6 0           up_sampling3d_137[0][0]          \n",
      "                                                                 conv3d_744[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_751 (Conv3D)             (None, 48, 48, 48, 2 326         concatenate_137[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_752 (Conv3D)             (None, 48, 48, 48, 2 110         conv3d_751[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_753 (Conv3D)             (None, 48, 48, 48, 1 3           conv3d_752[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 5,605\n",
      "Trainable params: 5,605\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "STEP=00000, loss=0.69027\n",
      "WARNING:tensorflow:9 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x15f0ffa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "(48, 48, 48, 1)\n",
      "(48, 48, 48, 1)\n",
      "STEP=00001, loss=0.68886\n",
      "(48, 48, 48, 1)\n",
      "(48, 48, 48, 1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    xt = nib.load(XT).get_fdata()\n",
    "    yt = nib.load(YT).get_fdata()\n",
    "    optimizer = tf.keras.optimizers.Adam(lr=0.001)\n",
    "    g = data_gen(DATA, SEG)\n",
    "    model = unet_model(1, 2)\n",
    "    model.summary()\n",
    "    for i in range(2):\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            xp, yp = next(g)\n",
    "            xp_out = model(xp, training=True)\n",
    "            xp_loss = tf.keras.losses.binary_crossentropy(yp, xp_out)\n",
    "        gradients = tape.gradient(xp_loss, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "        print(\"STEP=%05d, loss=%.5f\" % (\n",
    "            i,\n",
    "            np.mean(xp_loss.numpy())\n",
    "        )\n",
    "    )\n",
    "        if i % 1 == 0:\n",
    "            xp_save, yp = get_patch(xt, yt)\n",
    "            xp = xp_save.astype('float32')\n",
    "            pred = model.predict(xp[tf.newaxis, ...])\n",
    "            pred = tf.squeeze(pred, [0])\n",
    "            print(pred.shape)\n",
    "            print(pred.shape)\n",
    "            save_as_nifti(xp_save, os.path.join(OUT_DIR, 'pred'), '%d_x.nii.gz'% i)\n",
    "            save_as_nifti(pred, os.path.join(OUT_DIR, 'pred'), '%d_pred.nii.gz'% i)\n",
    "            save_as_nifti(np.round(pred), os.path.join(OUT_DIR, 'pred'), '%d_pred_rounded.nii.gz'% i)\n",
    "            save_as_nifti(yp, os.path.join(OUT_DIR, 'pred'), '%d_y.nii.gz'% i)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
